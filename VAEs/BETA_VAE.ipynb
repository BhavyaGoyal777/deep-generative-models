{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f45b9eae926d4695843fa6f9165c81ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8bbbe38f1b114d43972a8c7e1677b70c",
              "IPY_MODEL_de52353c8ead42d18e7f42880708676e",
              "IPY_MODEL_341674aa0c2648b9b3268ff638487c21"
            ],
            "layout": "IPY_MODEL_adc45bdb08db4196b17aae1da41241bd"
          }
        },
        "8bbbe38f1b114d43972a8c7e1677b70c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f91512e8560400e9eadfcdbed2a6718",
            "placeholder": "​",
            "style": "IPY_MODEL_cb1f10ede11349e890b76688cc6d3b95",
            "value": "Epoch 0/10: 100%"
          }
        },
        "de52353c8ead42d18e7f42880708676e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_087062920cd84ec691f2cf141b15b995",
            "max": 563,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e56b4967aca2498498e6b4a58cb1a19f",
            "value": 563
          }
        },
        "341674aa0c2648b9b3268ff638487c21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73c9aaf6ec024d288dda1a9029bd8cb9",
            "placeholder": "​",
            "style": "IPY_MODEL_af01c91e018148b5b33403d397537704",
            "value": " 563/563 [12:46&lt;00:00,  1.19s/it]"
          }
        },
        "adc45bdb08db4196b17aae1da41241bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f91512e8560400e9eadfcdbed2a6718": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb1f10ede11349e890b76688cc6d3b95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "087062920cd84ec691f2cf141b15b995": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e56b4967aca2498498e6b4a58cb1a19f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "73c9aaf6ec024d288dda1a9029bd8cb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af01c91e018148b5b33403d397537704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "067c79dfceb04cc98d28a57fc4d6ae36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b886b30642fb4f60ae928b1c86d2c71e",
              "IPY_MODEL_a183be8fa68e4a6ab3eeb8116d6ac211",
              "IPY_MODEL_22dcb2e19e574d4fbbee072e1c4e0209"
            ],
            "layout": "IPY_MODEL_c41e96ffbca04351970c2db9009f5e45"
          }
        },
        "b886b30642fb4f60ae928b1c86d2c71e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16b82a794df3425c893f901adac8c24d",
            "placeholder": "​",
            "style": "IPY_MODEL_1a0fa6a4d3574053a90f56c20213b0ec",
            "value": "Epoch 1/10:  46%"
          }
        },
        "a183be8fa68e4a6ab3eeb8116d6ac211": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f24b5d82568e443ba7d2cd22a216ba34",
            "max": 563,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_343297bdaea84a248b40bc6c1acd23da",
            "value": 261
          }
        },
        "22dcb2e19e574d4fbbee072e1c4e0209": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4304fd41cb364525aaa74121710dfae5",
            "placeholder": "​",
            "style": "IPY_MODEL_41b5aaabe31546738f04825eb331ad6d",
            "value": " 261/563 [05:55&lt;06:50,  1.36s/it]"
          }
        },
        "c41e96ffbca04351970c2db9009f5e45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16b82a794df3425c893f901adac8c24d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a0fa6a4d3574053a90f56c20213b0ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f24b5d82568e443ba7d2cd22a216ba34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "343297bdaea84a248b40bc6c1acd23da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4304fd41cb364525aaa74121710dfae5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41b5aaabe31546738f04825eb331ad6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "k-XuXL0Y3uLq"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the ZIP file\n",
        "zip_path = '/content/vae_data_archive.zip'\n",
        "\n",
        "# Destination directory to extract contents\n",
        "extract_to = 'vae_data'\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb lpips iq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cg7QOiLg4VjI",
        "outputId": "4196b2c4-ead3-412a-c707-40f9ea14c0aa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.21.0)\n",
            "Collecting lpips\n",
            "  Downloading lpips-0.1.4-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting iq\n",
            "  Downloading iq-0.0.2.tar.gz (1.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from wandb) (24.2)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.14.1)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from lpips) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from lpips) (0.21.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.11/dist-packages (from lpips) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from lpips) (1.15.3)\n",
            "Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.11/dist-packages (from lpips) (4.67.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.7.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=0.4.0->lpips)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=0.4.0->lpips)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=0.4.0->lpips)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=0.4.0->lpips)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=0.4.0->lpips)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=0.4.0->lpips)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=0.4.0->lpips)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=0.4.0->lpips)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=0.4.0->lpips)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=0.4.0->lpips)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=0.4.0->lpips) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.2.1->lpips) (11.2.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=0.4.0->lpips) (3.0.2)\n",
            "Downloading lpips-0.1.4-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: iq\n",
            "  Building wheel for iq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iq: filename=iq-0.0.2-py3-none-any.whl size=1349 sha256=6ed760a2f8c0669320e4f8da4724a392fbb9bc4c6f47b983dcf93f2f2406feaf\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/b3/39/68358dbaca7cda09c8c3be1f7f7ec9a51140cec1820c9e0cbf\n",
            "Successfully built iq\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, iq, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, lpips\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed iq-0.0.2 lpips-0.1.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision import datasets, transforms\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import lpips\n",
        "import wandb\n",
        "from dataclasses import dataclass, asdict\n",
        "from torch.amp.grad_scaler import GradScaler\n"
      ],
      "metadata": {
        "id": "oN-4moDv4gK8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class VAEConfig:\n",
        "    block_out_channel: tuple[int] = (64, 64, 128, 256)\n",
        "    input_channel: int = 3\n",
        "    output_channel: int = 3\n",
        "    latent_channel: int = 4\n",
        "    num_res_layers: int = 2\n",
        "    group_channels: int = 16\n",
        "    lr: float = 1e-4\n",
        "    beta: float = 0.7\n",
        "    epochs: int = 10\n",
        "    batch: int = 16\n",
        "    image_size: int = 128\n",
        "    folder_path: str = \"vae_data\"\n",
        "    train_split: float = 0.9\n"
      ],
      "metadata": {
        "id": "bqZF4zVO4jyj"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = VAEConfig()\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((config.image_size, config.image_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5] * 3, [0.5] * 3)\n",
        "])\n",
        "\n",
        "class ImageFolderDataset(Dataset):\n",
        "    def __init__(self, folder_path, transform=None):\n",
        "        self.folder_path = folder_path\n",
        "        self.image_files = [os.path.join(folder_path, f)\n",
        "                            for f in os.listdir(folder_path)\n",
        "                            if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.image_files[idx]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img\n",
        "\n",
        "dataset = ImageFolderDataset(config.folder_path, transform=transform)\n",
        "\n",
        "val_size = int(len(dataset) * (1 - config.train_split))\n",
        "train_size = len(dataset) - val_size\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=config.batch, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=config.batch, shuffle=False)\n",
        "\n",
        "fixed_val_batch = next(iter(val_loader))\n",
        "fixed_val_images = fixed_val_batch[:8].to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "HzhmZiBj4kzK"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ResnetBlock(nn.Module):\n",
        "  def __init__(self,\n",
        "               in_channel: int,\n",
        "               out_channel: int = None,\n",
        "               group_channel: int = 32,\n",
        "               drop: float = 0,\n",
        "               eps: float = 1e-5,\n",
        "              #  down: bool = False,\n",
        "              #  up: bool = False\n",
        "               ):\n",
        "    super().__init__()\n",
        "\n",
        "    out_channel = in_channel if out_channel is None else out_channel\n",
        "    self.out_channel = out_channel\n",
        "    self.norm1 = nn.GroupNorm(num_groups= group_channel, num_channels=in_channel, eps = eps)\n",
        "    self.norm2 = nn.GroupNorm(num_groups= group_channel, num_channels=out_channel, eps = eps)\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=1, padding=1)\n",
        "    self.conv2 = nn.Conv2d(out_channel, out_channel, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    self.act = nn.SiLU()\n",
        "    self.dropout = nn.Dropout(p=drop)\n",
        "\n",
        "    self.residual_layer = nn.Conv2d(in_channel, out_channel, kernel_size=1) if in_channel != out_channel else nn.Identity()\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    # x -> (b,c,h,w)\n",
        "    h = self.conv1(self.act(self.norm1(x))) # (b,c',h,w)\n",
        "    h = self.dropout(h)\n",
        "    h = self.conv2(self.act(self.norm2(h)))\n",
        "\n",
        "    x = self.residual_layer(x) + h\n",
        "    return x\n",
        "\n",
        "class Downsample(nn.Module):\n",
        "  def __init__(self,\n",
        "               in_channel: int,\n",
        "               out_channel: int = None,\n",
        "               use_conv:bool = False,\n",
        "               kernel:int = 3,\n",
        "               stride:int = 2\n",
        "               ):\n",
        "    super().__init__()\n",
        "\n",
        "    out_channel = in_channel if out_channel is None else out_channel\n",
        "    self.out_channel = out_channel\n",
        "    self.padding = kernel//2 #smooth padding\n",
        "    self.use_conv = use_conv\n",
        "\n",
        "    if use_conv:\n",
        "      self.down_layer = nn.Conv2d(in_channel, out_channel, kernel_size=kernel, stride=stride, padding=self.padding)\n",
        "    else:\n",
        "      self.down_layer = nn.AvgPool2d(kernel_size=stride, stride=stride)\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    #x -> (b,c,h,w)\n",
        "    if not self.use_conv:\n",
        "      pad = (0, 1, 0, 1)\n",
        "      x = torch.nn.functional.pad(x, pad, mode=\"constant\", value=0)\n",
        "    return self.down_layer(x)\n",
        "\n",
        "class Upsample(nn.Module):\n",
        "  def __init__(self,\n",
        "               in_channel: int,\n",
        "               out_channel: int = None,\n",
        "               use_conv:bool = False,\n",
        "               use_conv_tranpose:bool = False,\n",
        "               interpolate:bool = True\n",
        "               ):\n",
        "    super().__init__()\n",
        "\n",
        "    out_channel = in_channel if out_channel is None else out_channel\n",
        "    self.out_channel = out_channel\n",
        "    self.use_conv = use_conv\n",
        "    self.use_conv_tranpose = use_conv_tranpose\n",
        "    self.interpolate = interpolate\n",
        "\n",
        "    self.layer = None\n",
        "    if use_conv:\n",
        "      self.layer = nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=1, padding=1)\n",
        "    elif use_conv_tranpose:\n",
        "      self.layer = nn.ConvTranspose2d(in_channel, out_channel, kernel_size=4, stride=2, padding=1)\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    #x -> (b,c,h,w)\n",
        "\n",
        "    #simply using the tranpose conv\n",
        "    if self.use_conv_tranpose:\n",
        "      return self.layer(x)\n",
        "\n",
        "    if self.interpolate: #use interpolate and then option to use conv\n",
        "      x = nn.functional.interpolate(x, scale_factor=2, mode = 'nearest')\n",
        "\n",
        "    if self.use_conv:\n",
        "      x = self.layer(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "  def __init__(self,\n",
        "               num_res_layers:int,\n",
        "               in_channel:int,\n",
        "               out_channel:int,\n",
        "               group_channel:int,\n",
        "               drop:int = 0,\n",
        "               eps:float = 1e-5,\n",
        "               down_layer:bool = True,\n",
        "               ):\n",
        "    super().__init__()\n",
        "\n",
        "    self.down_layer = down_layer\n",
        "    self.layers = nn.ModuleList([])\n",
        "\n",
        "    for idx in range(num_res_layers):\n",
        "      in_channel = in_channel if idx == 0 else out_channel\n",
        "      self.layers.append(ResnetBlock(in_channel,out_channel,group_channel,drop, eps))\n",
        "\n",
        "    if self.down_layer:\n",
        "      self.down_block = Downsample(out_channel, use_conv=True)\n",
        "\n",
        "  def forward(self, x:torch.Tensor):\n",
        "\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "\n",
        "    if self.down_layer:\n",
        "      x = self.down_block(x)\n",
        "    return x\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "  def __init__(self,\n",
        "               num_res_layers:int,\n",
        "               in_channel:int,\n",
        "               out_channel:int,\n",
        "               group_channel:int,\n",
        "               drop:int = 0,\n",
        "               eps:float = 1e-5,\n",
        "               up_layer:bool = True\n",
        "               ):\n",
        "    super().__init__()\n",
        "\n",
        "    self.up_layer = up_layer\n",
        "\n",
        "    self.layers = nn.ModuleList([])\n",
        "\n",
        "    for idx in range(num_res_layers):\n",
        "      in_channel = in_channel if idx == 0 else out_channel\n",
        "      self.layers.append(ResnetBlock(in_channel,out_channel,group_channel,drop, eps))\n",
        "\n",
        "    if self.up_layer:\n",
        "      self.up_block = Upsample(out_channel, use_conv=True, interpolate=True)\n",
        "\n",
        "  def forward(self, x:torch.Tensor):\n",
        "\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "\n",
        "    if self.up_layer:\n",
        "      x = self.up_block(x)\n",
        "    return x\n",
        "\n",
        "#more type of block can be added here like attention_block\n",
        "class BottleNeck(nn.Module):\n",
        "  def __init__(self,\n",
        "              num_res_layers:int,\n",
        "              in_channel:int,\n",
        "              out_channel:int,\n",
        "              group_channel:int,\n",
        "              drop:int = 0,\n",
        "              eps:float = 1e-5):\n",
        "    super().__init__()\n",
        "\n",
        "    self.layers = nn.ModuleList([])\n",
        "\n",
        "    for idx in range(num_res_layers):\n",
        "      in_channel = in_channel if idx == 0 else out_channel\n",
        "      self.layers.append(ResnetBlock(in_channel,out_channel,group_channel,drop, eps))\n",
        "\n",
        "  def forward(self, x:torch.Tensor):\n",
        "\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "#Encoder block + bottleneck block\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                  block_out_channels:list[int],\n",
        "                  input_channel:int = 3,\n",
        "                  output_channel:int = 4, #latent channels\n",
        "                  num_res_layers:int = 2,\n",
        "                  group_channel: int =32,\n",
        "                  drop: float = 0,\n",
        "                  eps:float = 1e-5\n",
        "                  ):\n",
        "      super().__init__()\n",
        "\n",
        "      out_channel = block_out_channels[0]\n",
        "      in_channel = input_channel\n",
        "      #first layer for projection\n",
        "      self.first_layer = nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "      #encoder part\n",
        "      self.encoder_blocks = nn.ModuleList([])\n",
        "      for idx,_ in enumerate(block_out_channels):\n",
        "        in_channel = out_channel\n",
        "        # out_channel = block_out_channels[idx + 1] if idx < len(block_out_channels)-1 else in_channel\n",
        "        out_channel = block_out_channels[idx]\n",
        "        last_block = idx == len(block_out_channels)-1\n",
        "        self.encoder_blocks.append(EncoderBlock(num_res_layers,in_channel,out_channel,group_channel,drop,eps,not last_block))\n",
        "\n",
        "      #bottleneck part\n",
        "      final_channel = block_out_channels[-1]\n",
        "      self.bottleneck = BottleNeck(num_res_layers=num_res_layers,in_channel=final_channel,out_channel=final_channel,group_channel= group_channel,drop=drop,eps=eps)\n",
        "\n",
        "      self.latent_out = nn.Sequential(\n",
        "        nn.GroupNorm(num_groups=32, num_channels=block_out_channels[-1]),\n",
        "        nn.SiLU(),\n",
        "        nn.Conv2d(block_out_channels[-1], 2 * output_channel, kernel_size=3, padding=1)\n",
        "      )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "      x = self.first_layer(x)\n",
        "      for encoder_block in self.encoder_blocks:\n",
        "        x = encoder_block(x)\n",
        "\n",
        "      x = self.bottleneck(x)\n",
        "      return self.latent_out(x)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                  block_out_channels:list[int],\n",
        "                  input_channel:int = 4, #latent channels\n",
        "                  output_channel:int = 3,\n",
        "                  num_res_layers:int = 2,\n",
        "                  group_channel: int = 32,\n",
        "                  drop:float = 0,\n",
        "                  eps:float = 1e-5\n",
        "                  ):\n",
        "      super().__init__()\n",
        "\n",
        "      block_out_channels = block_out_channels[::-1]\n",
        "\n",
        "      out_channel = block_out_channels[0]\n",
        "      in_channel = input_channel\n",
        "      #first layer for projection\n",
        "      self.first_layer = nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "      #bottleneck part\n",
        "      final_channel = block_out_channels[0]\n",
        "      self.bottleneck = BottleNeck(num_res_layers=num_res_layers,in_channel=final_channel,out_channel=final_channel,group_channel= group_channel,drop=drop,eps=eps)\n",
        "\n",
        "      #encoder part\n",
        "      self.decoder_blocks = nn.ModuleList([])\n",
        "      for idx,_ in enumerate(block_out_channels):\n",
        "        in_channel = out_channel\n",
        "        # out_channel = block_out_channels[idx + 1] if idx < len(block_out_channels)-1 else in_channel\n",
        "        out_channel = block_out_channels[idx]\n",
        "        last_block = idx == len(block_out_channels)-1\n",
        "        self.decoder_blocks.append(DecoderBlock(num_res_layers,in_channel,out_channel,group_channel,drop,eps,not last_block))\n",
        "\n",
        "      self.image_out = nn.Sequential(\n",
        "        nn.GroupNorm(num_groups=32, num_channels=block_out_channels[-1]),\n",
        "        nn.SiLU(),\n",
        "        nn.Conv2d(block_out_channels[-1], output_channel, kernel_size=3, padding=1),\n",
        "        nn.Tanh()\n",
        "      )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "      x = self.first_layer(x)\n",
        "      x = self.bottleneck(x)\n",
        "      for decoder_block in self.decoder_blocks:\n",
        "        x = decoder_block(x)\n",
        "\n",
        "      return self.image_out(x)\n",
        "\n",
        "\n",
        "class VAE(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    block_out_channel = config.block_out_channel\n",
        "    input_channel = config.input_channel\n",
        "    output_channel = config.output_channel\n",
        "    latent_channel = config.latent_channel\n",
        "    num_res_layers = config.num_res_layers\n",
        "    group_channels = config.group_channels\n",
        "\n",
        "    self.encoder = Encoder(block_out_channels= block_out_channel,\n",
        "                           input_channel = input_channel,\n",
        "                           output_channel= latent_channel,\n",
        "                           num_res_layers= num_res_layers,\n",
        "                           group_channel= group_channels\n",
        "                           )\n",
        "    self.decoder = Decoder(\n",
        "                          block_out_channels= block_out_channel,\n",
        "                          input_channel = latent_channel,\n",
        "                          output_channel= output_channel,\n",
        "                          num_res_layers= num_res_layers,\n",
        "                          group_channel= group_channels\n",
        "                          )\n",
        "\n",
        "  def encode(self, x: torch.Tensor):\n",
        "    h = self.encoder(x)\n",
        "    #considering the covariance as diagonal (independent variables)\n",
        "    mu, log_var = torch.split(h, h.shape[1]//2, dim = 1) #splitting over the channel_dim\n",
        "    var = torch.exp(log_var)\n",
        "    std = torch.exp(0.5 * log_var)\n",
        "    z = mu + std * torch.randn_like(mu)\n",
        "    return z, mu, var\n",
        "\n",
        "  def decode(self, z: torch.Tensor):\n",
        "    x = self.decoder(z)\n",
        "    return x\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "\n",
        "    z, mu, var= self.encode(x)\n",
        "    x = self.decode(z)\n",
        "    return x, mu, var"
      ],
      "metadata": {
        "id": "nSRec7cD4l36"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae = VAE(config).to(\"cuda\")\n",
        "\n"
      ],
      "metadata": {
        "id": "0IRWcXGUBYKz"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eCF9O1xk4nAl",
        "outputId": "a12f7624-f3e7-4102-9c58-ab156e5efdba"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.utils import make_grid\n",
        "wandb.login(key=\"40155c09386ed20bd7ca7e488aa8f02a190ad188\")\n",
        "run = wandb.init(\n",
        "    project=\"vae-landscapes-256-pure-pytorch\",\n",
        "    config=asdict(config)\n",
        ")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# vae = VAE(config).to(device)\n",
        "scaler = GradScaler(device=device)\n",
        "\n",
        "optimizer_vae = optim.AdamW(vae.parameters(), lr=config.lr)\n",
        "recon_loss_fn = nn.L1Loss()\n",
        "lpips_fn = lpips.LPIPS(net='alex').to(device)\n",
        "\n",
        "def vae_loss(x, x_const, mu, var):\n",
        "    recon_loss = recon_loss_fn(x_const, x)\n",
        "    kl_loss = -0.5 * torch.mean(1 + torch.log(var) - mu**2 - var)\n",
        "    return recon_loss, kl_loss\n",
        "\n",
        "global_steps = 0\n",
        "for epoch in range(config.epochs):\n",
        "    vae.train()\n",
        "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch}/{config.epochs}\"):\n",
        "        global_steps += 1\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        with torch.autocast(device_type=device, dtype=torch.bfloat16):\n",
        "            x_const, mu, var = vae(batch)\n",
        "            recon_loss, kl_loss = vae_loss(batch, x_const, mu, var)\n",
        "            lpips_loss = lpips_fn(x_const, batch).mean()\n",
        "            total_loss = recon_loss + config.beta * kl_loss + lpips_loss\n",
        "\n",
        "        wandb.log({\n",
        "            \"loss/total_loss\": total_loss.item(),\n",
        "            \"loss/reconstr_loss\": recon_loss.item(),\n",
        "            \"loss/kl_loss\": kl_loss.item(),\n",
        "            \"lpips_loss\": lpips_loss.item()\n",
        "        }, step=global_steps)\n",
        "\n",
        "        optimizer_vae.zero_grad()\n",
        "        scaler.scale(total_loss).backward()\n",
        "        scaler.step(optimizer_vae)\n",
        "        scaler.update()\n",
        "\n",
        "    if (epoch + 1) % 1 == 0:\n",
        "        vae.eval()\n",
        "        with torch.no_grad():\n",
        "            # ----- Original + Reconstructed (2x8 grid) -----\n",
        "            x_const, _, _ = vae(fixed_val_images)\n",
        "            both = torch.cat([fixed_val_images, x_const], dim=0)\n",
        "            grid_both = make_grid(both.cpu() * 0.5 + 0.5, nrow=8)\n",
        "\n",
        "            # ----- Samples from Gaussian Prior (2x4 grid) -----\n",
        "            z = torch.randn(8, config.latent_channel, 16, 16).to(device)\n",
        "\n",
        "            sampled = vae.decode(z)\n",
        "            grid_sampled = make_grid(sampled.cpu() * 0.5 + 0.5, nrow=4)\n",
        "\n",
        "            wandb.log({\n",
        "                \"original_vs_reconstructed\": wandb.Image(grid_both),\n",
        "                \"sampled_from_gaussian\": wandb.Image(grid_sampled)\n",
        "            }, step=global_steps)\n",
        "\n",
        "        os.makedirs(\"checkpoints\", exist_ok=True)\n",
        "        torch.save(vae.state_dict(), f\"checkpoints/model_dict{epoch+10}.pth\")\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        mem_allocated = torch.cuda.memory_allocated(device) / 1024**2\n",
        "        mem_reserved = torch.cuda.memory_reserved(device) / 1024**2\n",
        "        print(f\"[Epoch {epoch}] GPU Memory: Allocated = {mem_allocated:.2f} MB, Reserved = {mem_reserved:.2f} MB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687,
          "referenced_widgets": [
            "f45b9eae926d4695843fa6f9165c81ba",
            "8bbbe38f1b114d43972a8c7e1677b70c",
            "de52353c8ead42d18e7f42880708676e",
            "341674aa0c2648b9b3268ff638487c21",
            "adc45bdb08db4196b17aae1da41241bd",
            "4f91512e8560400e9eadfcdbed2a6718",
            "cb1f10ede11349e890b76688cc6d3b95",
            "087062920cd84ec691f2cf141b15b995",
            "e56b4967aca2498498e6b4a58cb1a19f",
            "73c9aaf6ec024d288dda1a9029bd8cb9",
            "af01c91e018148b5b33403d397537704",
            "067c79dfceb04cc98d28a57fc4d6ae36",
            "b886b30642fb4f60ae928b1c86d2c71e",
            "a183be8fa68e4a6ab3eeb8116d6ac211",
            "22dcb2e19e574d4fbbee072e1c4e0209",
            "c41e96ffbca04351970c2db9009f5e45",
            "16b82a794df3425c893f901adac8c24d",
            "1a0fa6a4d3574053a90f56c20213b0ec",
            "f24b5d82568e443ba7d2cd22a216ba34",
            "343297bdaea84a248b40bc6c1acd23da",
            "4304fd41cb364525aaa74121710dfae5",
            "41b5aaabe31546738f04825eb331ad6d"
          ]
        },
        "id": "dm7U7gCY4o8v",
        "outputId": "7acac828-54c1-4186-9661-6d2fb0142a7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss/kl_loss</td><td>▁▃▂▂▅▂▅▂█▂▃▆▆▃▃▆▅▅▅▄▃▄▃▃▄▂▆▆▂▆▃▄▃▅▄▄▄▂▆▇</td></tr><tr><td>loss/reconstr_loss</td><td>▅█▅▂▄▅▄█▇▆▅▆▄▄▃▇▁▂▅▁▃▅▂▆▂▆▅▂▅▅▄▃▄▄▂▆▃▆▃▅</td></tr><tr><td>loss/total_loss</td><td>▅▅▇▄▇▅▇▆▅██▅▃▅▄▆▅▃▂▃▄▅▆█▆▃▇▆▃▁▄▅▆▅▅▄▄▂▃▄</td></tr><tr><td>lpips_loss</td><td>▅▄▆█▆▃▆▆▄▅▄▆▃▅▆▃▆▄▄▃▅▁▃▃▅▄▄▃▂▃▃▄▆▄▅▄▂▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss/kl_loss</td><td>0.16086</td></tr><tr><td>loss/reconstr_loss</td><td>0.15523</td></tr><tr><td>loss/total_loss</td><td>0.49732</td></tr><tr><td>lpips_loss</td><td>0.22949</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">brisk-cherry-32</strong> at: <a href='https://wandb.ai/777bhavya-dwarkadas-j-sanghvi-college-of-engineering/vae-landscapes-256-pure-pytorch/runs/4birvlwk' target=\"_blank\">https://wandb.ai/777bhavya-dwarkadas-j-sanghvi-college-of-engineering/vae-landscapes-256-pure-pytorch/runs/4birvlwk</a><br> View project at: <a href='https://wandb.ai/777bhavya-dwarkadas-j-sanghvi-college-of-engineering/vae-landscapes-256-pure-pytorch' target=\"_blank\">https://wandb.ai/777bhavya-dwarkadas-j-sanghvi-college-of-engineering/vae-landscapes-256-pure-pytorch</a><br>Synced 5 W&B file(s), 20 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250716_184823-4birvlwk/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250716_205717-k7y0hkrq</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/777bhavya-dwarkadas-j-sanghvi-college-of-engineering/vae-landscapes-256-pure-pytorch/runs/k7y0hkrq' target=\"_blank\">noble-blaze-39</a></strong> to <a href='https://wandb.ai/777bhavya-dwarkadas-j-sanghvi-college-of-engineering/vae-landscapes-256-pure-pytorch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/777bhavya-dwarkadas-j-sanghvi-college-of-engineering/vae-landscapes-256-pure-pytorch' target=\"_blank\">https://wandb.ai/777bhavya-dwarkadas-j-sanghvi-college-of-engineering/vae-landscapes-256-pure-pytorch</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/777bhavya-dwarkadas-j-sanghvi-college-of-engineering/vae-landscapes-256-pure-pytorch/runs/k7y0hkrq' target=\"_blank\">https://wandb.ai/777bhavya-dwarkadas-j-sanghvi-college-of-engineering/vae-landscapes-256-pure-pytorch/runs/k7y0hkrq</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 0/10:   0%|          | 0/563 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f45b9eae926d4695843fa6f9165c81ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 0] GPU Memory: Allocated = 1213.95 MB, Reserved = 6098.00 MB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 1/10:   0%|          | 0/563 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "067c79dfceb04cc98d28a57fc4d6ae36"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JtupWXY2EF5S"
      },
      "execution_count": 30,
      "outputs": []
    }
  ]
}